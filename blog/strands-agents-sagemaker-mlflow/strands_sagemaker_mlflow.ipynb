{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f8d710f-c953-4b87-8171-769a64488cc2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-29T16:02:54.086972Z",
          "iopub.status.busy": "2025-09-29T16:02:54.086215Z",
          "iopub.status.idle": "2025-09-29T16:02:54.091963Z",
          "shell.execute_reply": "2025-09-29T16:02:54.091058Z",
          "shell.execute_reply.started": "2025-09-29T16:02:54.086941Z"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "strands-agents>=1.9.1\n",
        "strands-agents-tools>=0.2.8\n",
        "mlflow>=3.4.0\n",
        "mlflow-sagemaker>=1.5.11\n",
        "strands-agents[sagemaker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f264f6c-59fb-47a4-9794-3c3b0ad72600",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-29T16:02:56.065983Z",
          "iopub.status.busy": "2025-09-29T16:02:56.065597Z",
          "iopub.status.idle": "2025-09-29T16:02:56.994652Z",
          "shell.execute_reply": "2025-09-29T16:02:56.993758Z",
          "shell.execute_reply.started": "2025-09-29T16:02:56.065945Z"
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9634ad2-a018-4220-be26-11a9036fb3cd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-28T22:31:03.748269Z",
          "iopub.status.busy": "2025-09-28T22:31:03.747964Z",
          "iopub.status.idle": "2025-09-28T22:31:03.921136Z",
          "shell.execute_reply": "2025-09-28T22:31:03.920283Z",
          "shell.execute_reply.started": "2025-09-28T22:31:03.748243Z"
        }
      },
      "outputs": [],
      "source": [
        "cat requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a7badde-eac2-4f58-acde-a30a0b701c20",
      "metadata": {},
      "source": [
        "## Beginning with Stands Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a7f52f-a5f7-424d-a73e-c72d7543bf9a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:12:32.574340Z",
          "iopub.status.busy": "2025-09-30T20:12:32.573781Z",
          "iopub.status.idle": "2025-09-30T20:12:44.984962Z",
          "shell.execute_reply": "2025-09-30T20:12:44.984148Z",
          "shell.execute_reply.started": "2025-09-30T20:12:32.574310Z"
        }
      },
      "outputs": [],
      "source": [
        "from strands import Agent, tool\n",
        "from strands_tools import http_request, calculator\n",
        "from strands.models import BedrockModel\n",
        "\n",
        "model = BedrockModel(\n",
        "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
        ")\n",
        "\n",
        "agent = Agent(model=model, tools=[http_request])\n",
        "agent(\"Where is the international space station now?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022f0356-416a-4a10-8bbd-0893958ace55",
      "metadata": {},
      "source": [
        "## Deploy Model as SageMaker AI Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fc3b33-5e90-4ecb-bf8f-be6ad725df09",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-09-30T20:12:27.904325Z",
          "iopub.status.idle": "2025-09-30T20:12:27.904703Z",
          "shell.execute_reply": "2025-09-30T20:12:27.904535Z",
          "shell.execute_reply.started": "2025-09-30T20:12:27.904517Z"
        }
      },
      "outputs": [],
      "source": [
        "# Deploy initial endpoint with Qwen-4B\n",
        "import boto3\n",
        "from boto3.session import Session\n",
        "from sagemaker.jumpstart.model import JumpStartModel\n",
        "\n",
        "boto_session = Session()\n",
        "sts = boto3.client('sts')\n",
        "account_id = sts.get_caller_identity().get(\"Account\")\n",
        "region = boto_session.region_name\n",
        "\n",
        "ENDPOINT_NAME = INITIAL_CONFIG_NAME = \"llm-endpoint-sagemaker\" # We will keep using this endpoint name\n",
        "\n",
        "model_a = JumpStartModel(\n",
        "    model_id=\"huggingface-reasoning-qwen3-4b\", \n",
        "    model_version=\"1.0.0\",\n",
        "    name=\"qwen-4b-model\"\n",
        ")\n",
        "\n",
        "# Deploy the model to an endpoint\n",
        "predictor_a = model_a.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type=\"ml.g5.2xlarge\",\n",
        "    endpoint_name=ENDPOINT_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e167d38e-429b-4b33-9362-8e08bcebe5d4",
      "metadata": {},
      "source": [
        "## Use SageMaker LLM endpoint with Strands Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54579d43-3faa-498b-897f-f789deb0af22",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T19:45:18.781756Z",
          "iopub.status.busy": "2025-09-30T19:45:18.781442Z",
          "iopub.status.idle": "2025-09-30T19:45:51.385693Z",
          "shell.execute_reply": "2025-09-30T19:45:51.384371Z",
          "shell.execute_reply.started": "2025-09-30T19:45:18.781734Z"
        }
      },
      "outputs": [],
      "source": [
        "from strands.models.sagemaker import SageMakerAIModel\n",
        "from strands import Agent, tool\n",
        "from strands_tools import http_request, calculator\n",
        "\n",
        "model_sagemaker = SageMakerAIModel(\n",
        "    endpoint_config={\n",
        "        \"endpoint_name\": ENDPOINT_NAME,\n",
        "        \"region_name\": region\n",
        "    },\n",
        "    payload_config={\n",
        "        \"max_tokens\": 2048,\n",
        "        \"temperature\": 0.2,\n",
        "        \"stream\": True,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Test the agent\n",
        "agent = Agent(model=model_sagemaker, tools=[http_request])\n",
        "agent(\"Where is the international space station now? (Use: http://api.open-notify.org/iss-now.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa949c8-3984-42a2-b711-931d5d25c2f1",
      "metadata": {},
      "source": [
        "## Creating MLflow Tracking Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a318c066-2c45-482c-9df8-b71c82a0fe29",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T15:35:37.737291Z",
          "iopub.status.busy": "2025-09-30T15:35:37.737039Z",
          "iopub.status.idle": "2025-09-30T15:35:39.244080Z",
          "shell.execute_reply": "2025-09-30T15:35:39.243245Z",
          "shell.execute_reply.started": "2025-09-30T15:35:37.737270Z"
        }
      },
      "outputs": [],
      "source": [
        "# MLflow config\n",
        "# It can be converted to create a new tracking server from code.\n",
        "import mlflow\n",
        "import os\n",
        "\n",
        "# Create MLflow tracking server\n",
        "response = sagemaker_client.create_mlflow_tracking_server(\n",
        "    TrackingServerName='strands-mlflow-server',\n",
        "    ArtifactStoreUri=f's3://{account_id}-mlflow-bucket/artifacts',\n",
        "    RoleArn=role,\n",
        "    TrackingServerSize='Small',  # Small, Medium, or Large\n",
        "    WeeklyMaintenanceWindowStart='Tue:03:30'\n",
        ")\n",
        "\n",
        "server_info = sagemaker_client.describe_mlflow_tracking_server(\n",
        "    TrackingServerName='strands-mlflow-server'\n",
        ")\n",
        "\n",
        "tracking_uri = server_info['TrackingServerArn']\n",
        "os.environ[\"MLFLOW_TRACKING_URI\"] = tracking_uri\n",
        "# Or you can set the tracking server as below.\n",
        "#mlflow.set_tracking_uri(tracking_uri)\n",
        "\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow Tracking Server URL: {tracking_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c68d89f-f3a0-41c4-bfd2-e5de5e3fde88",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T19:39:33.237684Z",
          "iopub.status.busy": "2025-09-30T19:39:33.237166Z",
          "iopub.status.idle": "2025-09-30T19:39:35.238181Z",
          "shell.execute_reply": "2025-09-30T19:39:35.237289Z",
          "shell.execute_reply.started": "2025-09-30T19:39:33.237656Z"
        }
      },
      "outputs": [],
      "source": [
        "# IF MLFLOW TRACKING SERVER ALREADY EXISTS, USE FOLLOWING CODE INSTEAD\n",
        "import mlflow\n",
        "tracking_uri = \"<TRACKING_SERVER_ARN>\"\n",
        "mlflow.set_tracking_uri(tracking_uri)\n",
        "print(f\"MLflow Tracking Server URL: {tracking_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab5f401-2eee-466d-90b6-50c29d0edfdf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T15:35:39.432211Z",
          "iopub.status.busy": "2025-09-30T15:35:39.431921Z",
          "iopub.status.idle": "2025-09-30T15:35:39.492714Z",
          "shell.execute_reply": "2025-09-30T15:35:39.491882Z",
          "shell.execute_reply.started": "2025-09-30T15:35:39.432189Z"
        }
      },
      "source": [
        "## Run the agent with MLflow tracing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ab1cd55-3cec-42dc-9b90-624339bf551b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:12:57.755469Z",
          "iopub.status.busy": "2025-09-30T20:12:57.755174Z",
          "iopub.status.idle": "2025-09-30T20:12:59.211508Z",
          "shell.execute_reply": "2025-09-30T20:12:59.210935Z",
          "shell.execute_reply.started": "2025-09-30T20:12:57.755448Z"
        }
      },
      "outputs": [],
      "source": [
        "# Create a new experiment and start logging\n",
        "import mlflow\n",
        "mlflow.set_experiment(\"Strands_Agents_prod\")\n",
        "mlflow.strands.autolog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1144ccd-7492-4348-8714-fbd4f3a3025b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:13:03.043717Z",
          "iopub.status.busy": "2025-09-30T20:13:03.043257Z",
          "iopub.status.idle": "2025-09-30T20:13:03.142678Z",
          "shell.execute_reply": "2025-09-30T20:13:03.141394Z",
          "shell.execute_reply.started": "2025-09-30T20:13:03.043681Z"
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Run the agent, and apply post-processing to the result\n",
        "from strands import Agent, tool\n",
        "\n",
        "def capitalize(response):\n",
        "    return response.upper()\n",
        "    \n",
        "agent = Agent(model=model_sagemaker, tools=[http_request])\n",
        "response = agent(\"Where is the international space station now? (Use: http://api.open-notify.org/iss-now.json\")\n",
        "capitalize(response.message['content'][0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa04bf3f-2d3f-4ef3-ba7b-31503408263f",
      "metadata": {},
      "source": [
        "## Explicit tracing using @mlflow.trace decorator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7ec50a-0e63-485f-aa5e-4e694f2b3b80",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T19:50:04.425982Z",
          "iopub.status.busy": "2025-09-30T19:50:04.423990Z",
          "iopub.status.idle": "2025-09-30T19:50:14.233784Z",
          "shell.execute_reply": "2025-09-30T19:50:14.233023Z",
          "shell.execute_reply.started": "2025-09-30T19:50:04.425942Z"
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "@mlflow.trace(span_type=\"func\", attributes={\"operation\": \"capitalize\"})\n",
        "def capitalize(response):\n",
        "    return response.upper()\n",
        "\n",
        "@mlflow.trace\n",
        "def run_agent():\n",
        "    agent = Agent(tools=[http_request])\n",
        "    response = agent(\"Where is the international space station now?\")\n",
        "    capitalized_response = capitalize(response.message['content'][0]['text'])\n",
        "\n",
        "    return capitalized_response\n",
        "\n",
        "# Execute the traced function\n",
        "capitalized_response = run_agent()\n",
        "print(capitalized_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92cb042e-c9f6-43a3-bf04-b4482d655b9b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-29T21:06:59.753712Z",
          "iopub.status.busy": "2025-09-29T21:06:59.753295Z",
          "iopub.status.idle": "2025-09-29T21:17:32.223135Z",
          "shell.execute_reply": "2025-09-29T21:17:32.222104Z",
          "shell.execute_reply.started": "2025-09-29T21:06:59.753687Z"
        }
      },
      "source": [
        "## Deploy a new LLM for A/B testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dcf6042-e410-48e6-8e6e-2888d530de58",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:17:32.634685Z",
          "iopub.status.busy": "2025-09-30T20:17:32.633890Z",
          "iopub.status.idle": "2025-09-30T20:17:33.878892Z",
          "shell.execute_reply": "2025-09-30T20:17:33.877876Z",
          "shell.execute_reply.started": "2025-09-30T20:17:32.634652Z"
        }
      },
      "outputs": [],
      "source": [
        "# Step1: Create a model from JumpStart\n",
        "import boto3\n",
        "from sagemaker.jumpstart.model import JumpStartModel\n",
        "model_b_name  =\"sagemaker-strands-demo-qwen3-8b\"\n",
        "model_b_id, model_b_version = \"huggingface-reasoning-qwen3-8b\", \"1.0.0\"\n",
        "\n",
        "model_b = JumpStartModel(\n",
        "    model_id=\"huggingface-reasoning-qwen3-8b\",  \n",
        "    model_version=\"1.0.0\",\n",
        "    name=model_b_name\n",
        ")\n",
        "model_b.create(instance_type=\"ml.g5.2xlarge\")\n",
        "\n",
        "# Step2: Create production variants for A/B testing\n",
        "# Create production variants for A/B testing\n",
        "production_variants = [\n",
        "   # The original model (champion)\n",
        "   {\n",
        "        \"VariantName\": \"qwen-4b-variant\",\n",
        "        \"ModelName\": \"qwen-4b-model\",\n",
        "        \"InitialInstanceCount\": 1,\n",
        "        \"InstanceType\": \"ml.g5.2xlarge\",\n",
        "        \"InitialVariantWeight\": 0.5  # It will take 50% of the traffic\n",
        "    },\n",
        "   # The new model (challenger)\n",
        "    {\n",
        "        \"VariantName\": \"qwen-8b-variant\",\n",
        "        \"ModelName\": model_b_name,\n",
        "        \"InitialInstanceCount\": 1,\n",
        "        \"InstanceType\": \"ml.g5.2xlarge\",\n",
        "        \"InitialVariantWeight\": 0.5  # It will take 50% of the traffic\n",
        "    }\n",
        "]\n",
        "\n",
        "# Step3: Create new endpoint configuration\n",
        "sagemaker_client = boto3.client('sagemaker')\n",
        "ENDPOINT_CONFIG_AB_TESTING = \"llm-endpoint-config-ab\"\n",
        "sagemaker_client.create_endpoint_config(\n",
        "    EndpointConfigName=ENDPOINT_CONFIG_AB_TESTING,\n",
        "    ProductionVariants=production_variants\n",
        ")\n",
        "\n",
        "# Step4: Update the endpoint with new A/B testing configuration\n",
        "sagemaker_client.update_endpoint(\n",
        "    EndpointName=ENDPOINT_NAME, #Remember, the endpoint name stays the same\n",
        "    EndpointConfigName=ENDPOINT_CONFIG_AB_TESTING\n",
        ")\n",
        "\n",
        "# Wait until the update is completed\n",
        "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
        "waiter.wait(EndpointName=ENDPOINT_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b32777-5a1a-4a04-8d10-e5a795eec59d",
      "metadata": {},
      "source": [
        "## Controlled experiment using explicit variants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4194f8b8-59d2-493e-9a6f-1e30b93d8bf6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:15:47.762365Z",
          "iopub.status.busy": "2025-09-30T20:15:47.761787Z",
          "iopub.status.idle": "2025-09-30T20:15:47.921635Z",
          "shell.execute_reply": "2025-09-30T20:15:47.920921Z",
          "shell.execute_reply.started": "2025-09-30T20:15:47.762340Z"
        }
      },
      "outputs": [],
      "source": [
        "# Create SaegMaker models for A/B testing\n",
        "from strands.models.sagemaker import SageMakerAIModel\n",
        "from strands import Agent, tool\n",
        "from strands_tools import http_request, calculator\n",
        "\n",
        "model_sagemaker_a = SageMakerAIModel(\n",
        "    endpoint_config={\n",
        "        \"endpoint_name\": ENDPOINT_NAME,\n",
        "        \"region_name\": region,\n",
        "        \"target_variant\":\"qwen-4b-variant\"\n",
        "    },\n",
        "    payload_config={\n",
        "        \"max_tokens\": 2048,\n",
        "        \"temperature\": 0.2,\n",
        "        \"stream\": True,\n",
        "    }\n",
        ")\n",
        "\n",
        "model_sagemaker_b = SageMakerAIModel(\n",
        "    endpoint_config={\n",
        "        \"endpoint_name\": ENDPOINT_NAME,\n",
        "        \"region_name\": region,\n",
        "        \"target_variant\":\"qwen-8b-variant\"\n",
        "    },\n",
        "    payload_config={\n",
        "        \"max_tokens\": 2048,\n",
        "        \"temperature\": 0.2,\n",
        "        \"stream\": True,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecca2069-6316-49d2-a6e9-14b578901f16",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:15:57.910443Z",
          "iopub.status.busy": "2025-09-30T20:15:57.909746Z",
          "iopub.status.idle": "2025-09-30T20:16:52.678791Z",
          "shell.execute_reply": "2025-09-30T20:16:52.677988Z",
          "shell.execute_reply.started": "2025-09-30T20:15:57.910414Z"
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "mlflow.set_experiment(\"Strands_Agents_AB_testing\") # Start a new experiement\n",
        "\n",
        "with mlflow.start_span(): # For \"A\" variant.\n",
        "    mlflow.update_current_trace(tags={\"variant\": \"qwen-4b\"})\n",
        "    agent = Agent(model=model_sagemaker_a, tools=[http_request])\n",
        "    agent(\"Where is the international space station now. (Use: http://api.open-notify.org/iss-now.json)\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "#time.sleep(5) # Pause shortly before running the other variant.\n",
        "\n",
        "with mlflow.start_span(): # For \"B\" variant.\n",
        "    mlflow.update_current_trace(tags={\"variant\": \"qwen-8b\"})\n",
        "    agent = Agent(model=model_sagemaker_b, tools=[http_request])\n",
        "    agent(\"Where is the international space station now. (Use: http://api.open-notify.org/iss-now.json)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64fef224-1500-42a1-8641-e8577bef3ea5",
      "metadata": {},
      "source": [
        "## Transition to the new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d889930a-d569-4427-91c5-47fb5edf48ea",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:17:53.362060Z",
          "iopub.status.busy": "2025-09-30T20:17:53.361778Z",
          "iopub.status.idle": "2025-09-30T20:17:54.261972Z",
          "shell.execute_reply": "2025-09-30T20:17:54.261256Z",
          "shell.execute_reply.started": "2025-09-30T20:17:53.362041Z"
        }
      },
      "outputs": [],
      "source": [
        "production_variants = [\n",
        "    {\n",
        "        \"VariantName\": \"qwen-8b-variant\",\n",
        "        \"ModelName\": model_b_name,\n",
        "        \"InitialInstanceCount\": 1,\n",
        "        \"InstanceType\": \"ml.g5.2xlarge\",\n",
        "        \"InitialVariantWeight\": 1\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create new endpoint configuration\n",
        "NEW_ENDPOINT_CONFIG = \"llm-endpoint-config-qwen-8b\"\n",
        "sagemaker_client.create_endpoint_config(\n",
        "    EndpointConfigName=NEW_ENDPOINT_CONFIG,\n",
        "    ProductionVariants=production_variants\n",
        ")\n",
        "\n",
        "\n",
        "# Update the endpoint to use new configuration\n",
        "sagemaker_client.update_endpoint(\n",
        "    EndpointName=ENDPOINT_NAME,\n",
        "    EndpointConfigName=NEW_ENDPOINT_CONFIG\n",
        ")\n",
        "# Wait until the update is completed\n",
        "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
        "waiter.wait(EndpointName=ENDPOINT_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1df0d90-fcfd-40a3-9aaf-838770cd1b45",
      "metadata": {},
      "source": [
        "## Clean up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779f503f-cf7e-4e58-b599-1ee2c85fc665",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-30T20:18:18.447808Z",
          "iopub.status.busy": "2025-09-30T20:18:18.447521Z",
          "iopub.status.idle": "2025-09-30T20:18:18.614707Z",
          "shell.execute_reply": "2025-09-30T20:18:18.613710Z",
          "shell.execute_reply.started": "2025-09-30T20:18:18.447787Z"
        }
      },
      "outputs": [],
      "source": [
        "sagemaker_client.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
        "sagemaker_client.delete_endpoint_config(EndpointConfigName=INITIAL_CONFIG_NAME)\n",
        "sagemaker_client.delete_endpoint_config(EndpointConfigName=ENDPOINT_CONFIG_AB_TESTING)\n",
        "sagemaker_client.delete_endpoint_config(EndpointConfigName=NEW_ENDPOINT_CONFIG)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}