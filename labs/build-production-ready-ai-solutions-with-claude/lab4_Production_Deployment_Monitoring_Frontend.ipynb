{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "## Lab 4: Deploy to Production - Use AgentCore Runtime with Observability and a Frontend Application\n",
    "\n",
    "### Overview\n",
    "\n",
    "In Lab 3 we designed robust architectures with Retrieval Augemented Generation (RAG), Agentic AI using Strands and security with Guardrails. In this Lab, we will see how to deploy an Agent to production using AgentCore Runtime with secure authentication, memory and comprehensive observability. This will transform our prototype into a production-ready system that can handle real-world traffic with full monitoring and automatic scaling.\n",
    "\n",
    "[Amazon Bedrock AgentCore Runtime](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/agents-tools-runtime.html) is a secure, fully managed runtime that empowers organizations to deploy and scale AI agents in production, regardless of framework, protocol, or model choice. It provides enterprise-grade reliability, automatic scaling, and comprehensive monitoring capabilities.\n",
    "\n",
    "**Workshop Journey:**\n",
    "\n",
    "- **Lab 1 (Done):** Getting Started with Bedrock APIs - Learned basic API calls, streaming responses, and conversational interactions using Claude Haiku 4.5\n",
    "- **Lab 2 (Done):** Prompt Engineering - Mastered system prompts, structured output, zero-shot/few-shot prompting, and chain-of-thought reasoning\n",
    "- **Lab 3 (Done):** Enterprise Bedrock Architectures with Claude Models - Built RAG with Knowledge Base, implemented Agentic AI using Strands framework, and configured security with Guardrails\n",
    "- **Lab 4 (Current):** Production Deployment with Monitoring & Frontend - Deploy agents to production using AgentCore Runtime with comprehensive observability, secure authentication with Cognito, and create a customer-facing Streamlit frontend application\n",
    "- **Lab 5:** Cost Optimization - Implement dynamic model selection with prompt routing, optimize prompts and outputs, leverage caching strategies, and use batch processing for non-real-time scenarios\n",
    "\n",
    "### Why AgentCore Runtime & Production Deployment Matter\n",
    "\n",
    "Current State: Agent runs locally with centralized tools but faces production challenges:\n",
    "\n",
    "- No comprehensive monitoring or debugging capabilities\n",
    "- The agents cannot scale in or out automatically as traffic increases or decreases.\n",
    "\n",
    "After this lab, we will have a production-ready agent infrastructure with:\n",
    "\n",
    "- Serverless auto-scaling to handle variable demand\n",
    "- Comprehensive observability with traces, metrics, and logging\n",
    "- Enterprise reliability with automatic error recovery\n",
    "- Secure deployment with proper access controls\n",
    "- Easy management through AWS console and APIs and support for real-world production workloads.\n",
    "\n",
    "\n",
    "### Adding comprehensive observability with AgentCore Observability\n",
    "\n",
    "Additionally, AgentCore Runtime integrates seamlessly with [AgentCore Observability](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/observability.html) to provide full visibility into your agent's behavior in production. AgentCore Observability automatically captures traces, metrics, and logs from your agent interactions, tool usage, and memory access patterns. In this lab we will see how AgentCore Runtime integrates with CloudWatch GenAI Observability to provide comprehensive monitoring and debugging capabilities.\n",
    "\n",
    "For request tracing, AgentCore Observability captures the complete conversation flow including tool invocations, memory retrievals, and model interactions. For performance monitoring, it tracks response times, success rates, and resource utilization to help optimize your agent's performance.\n",
    "\n",
    "During the observability flow, AgentCore Runtime automatically instruments your agent code and sends telemetry data to CloudWatch. You can then use CloudWatch dashboards and GenAI Observability features to analyze patterns, identify bottlenecks, and troubleshoot issues in real-time.\n",
    "\n",
    "### Architecture for Lab 4\n",
    "<div style=\"text-align:left\"> \n",
    "    <img src=\"images/lab4_architecture_runtime.png\" width=\"75%\"/> \n",
    "</div>\n",
    "\n",
    "*Agent now runs in AgentCore Runtime with full observability through CloudWatch, serving production traffic with auto-scaling and comprehensive monitoring.AgentCore Memory enables the AI agent to maintain context over time, remember important facts, and deliver consistent, personalized experiences.*\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **Serverless Agent Deployment:** Transform your local agent into a scalable production service using AgentCore Runtime with minimal code changes\n",
    "- **Comprehensive Observability:** Full request tracing, performance metrics, and debugging capabilities through CloudWatch GenAI Observability\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.12+\n",
    "- AWS account with appropriate permissions\n",
    "- Docker, Finch or Podman installed and running\n",
    "- Amazon Bedrock AgentCore SDK\n",
    "- Strands Agents framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867d862-3b01-4b97-ac00-0ff38ff57fc0",
   "metadata": {},
   "source": [
    "### Step 1: Install Dependencies and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14e13c-1032-4690-8ae0-6b269d57f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -U -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from utils import get_param_value\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "sts = session.client('sts')\n",
    "identity = sts.get_caller_identity()\n",
    "account_id = identity['Account']\n",
    "region = boto3.Session().region_name or 'us-west-2'\n",
    "\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c1577-8a12-4bb5-9fc7-4e9b6bd5975b",
   "metadata": {},
   "source": [
    "#### Step 1.5 Prepare Memory and Knowledgebase\n",
    "\n",
    "**Note:** The following cell might take a few minutes to run. Please be patient.  \n",
    "\n",
    "While this is running, click on the **Chat icon on the left bar** ‚Äî this is **Amazon Q**, where you can ask questions about any AWS service, request code snippets, and more.  \n",
    "\n",
    "While we wait for the cell to finish, you can ask questions like:  \n",
    "- *What is Bedrock AgentCore Memory?*  \n",
    "- *Why is it needed?*  \n",
    "- *What are the various types of Memory?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ab7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit.operations.memory.manager import MemoryManager\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore.memory.constants import StrategyType\n",
    "\n",
    "MEMORY_NAME=\"ReturnRefundAssisantMemory\"\n",
    "\n",
    "memory_manager = MemoryManager(region_name=region)\n",
    "\n",
    "# Create or get memory with strategies\n",
    "memory = memory_manager.get_or_create_memory(\n",
    "    name=MEMORY_NAME,\n",
    "    description=\"Memory for returns and refunds assistant\",\n",
    "    strategies=[\n",
    "                {\n",
    "                    StrategyType.USER_PREFERENCE.value: {\n",
    "                        \"name\": \"CustomerPreferences\",\n",
    "                        \"description\": \"Captures customer preferences and behavior\",\n",
    "                        \"namespaces\": [\"returns/customer/{actorId}/preferences\"],\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    StrategyType.SEMANTIC.value: {\n",
    "                        \"name\": \"CustomerSupportSemantic\",\n",
    "                        \"description\": \"Stores facts from conversations\",\n",
    "                        \"namespaces\": [\"returns/customer/{actorId}/semantic\"],\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    ")\n",
    "\n",
    "memory_id = memory[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb588c8-85de-4b3d-9652-cb278c27062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the knowledge base ID from AWS Systems Manager Parameter Store\n",
    "\n",
    "kb_id = get_param_value(f\"/app/workshop/kb/knowledge-base-id\")\n",
    "print(f\"Knowledge Base ID: {kb_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "### Step 2: Preparing Your Agent for AgentCore Runtime\n",
    "\n",
    "#### Creating the Runtime-Ready Agent\n",
    "\n",
    "Let's first define the necessary AgentCore Runtime components via Python SDK within our previous local agent implementation.\n",
    "\n",
    "Observe the `#### AGENTCORE RUNTIME - LINE i ####` comments below to see where is the relevant deployment code added. You'll find 4 such lines that prepare the runtime-ready agent:\n",
    "\n",
    "1. Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "2. Initialize the App with `app = BedrockAgentCoreApp()`\n",
    "3. Decorate our invocation function with `@app.entrypoint`\n",
    "4. Let AgentCore Runtime control the execution with `app.run()`\n",
    "\n",
    "#### The magic command writefile writes the code in this cell to a py file. This is our agent code that we will push to AgentCore Runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07fb75-b189-4db0-9e53-ee0c3caebdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./lab4_runtime.py\n",
    "import os\n",
    "from bedrock_agentcore.runtime import (\n",
    "    BedrockAgentCoreApp,\n",
    ")  #### AGENTCORE RUNTIME - LINE 1 ####\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands_tools import retrieve, current_time\n",
    "from bedrock_agentcore.memory.integrations.strands.config import AgentCoreMemoryConfig, RetrievalConfig\n",
    "from bedrock_agentcore.memory.integrations.strands.session_manager import AgentCoreMemorySessionManager\n",
    "from utils import get_param_value\n",
    "from utils.agent_memory import REGION, SESSION_ID, ACTOR_ID\n",
    "\n",
    "\n",
    "MODEL_ID = \"us.anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=MODEL_ID,\n",
    "    temperature=0.3,\n",
    "\n",
    ")\n",
    "\n",
    "# Initialize the AgentCore Runtime App\n",
    "app = BedrockAgentCoreApp()  #### AGENTCORE RUNTIME - LINE 2 ####\n",
    "\n",
    "kb_id = os.environ.get(\"KNOWLEDGE_BASE_ID\", \"NOT AVAILABLE\")\n",
    "\n",
    "system_prompt=f\"\"\"\n",
    "You are an Amazon Returns & Refunds assistant.\n",
    "\n",
    "Do not answer based on your own knowledge.  \n",
    "You have access to relevant policy from retrieve from a knowledge base. (KNOWLEDGE_BASE_ID=\"{kb_id}\")\n",
    "You have access to memory regarding customers purchase history and preferences.\n",
    "Retrieve and check the relevant policies firstly for return * refund requests.\n",
    "Use metadata filtering to get policies for proper country where customer had transactions.\n",
    "[Metadata]\n",
    "{{\n",
    "    \"country\": <ISO2 Country Code> // e.g. \"US\", \"UK\", \"IN\"\n",
    "}}\n",
    "\n",
    "When a user asks about returns or refunds, use the content to give accurate advice.\n",
    "Always be accurate, concise, and do not deviate from known policies.\n",
    "\"\"\"\n",
    "# Add Memory\n",
    "# Get memory ID from environment variable\n",
    "\n",
    "\n",
    "\n",
    "memory_id = os.environ.get(\"MEMORY_ID\")\n",
    "if not memory_id:\n",
    "    raise Exception(\"Environment variable MEMORY_ID is required\")\n",
    "\n",
    "\n",
    "@app.entrypoint  #### AGENTCORE RUNTIME - LINE 3 ####\n",
    "def invoke(payload, context=None):\n",
    "    \"\"\"AgentCore Runtime entrypoint function\"\"\"\n",
    "    \n",
    "    # session_id tracks the conversation context for the model, and actor_id identifies the user or agent \n",
    "    # interacting with the AgentCore runtime.\n",
    "\n",
    "    session_id = context.session_id if context else SESSION_ID\n",
    "    actor_id = payload.get(\"actor_id\", ACTOR_ID) \n",
    "\n",
    "    # Configure memory\n",
    "    agentcore_memory_config = AgentCoreMemoryConfig(\n",
    "        memory_id=memory_id,\n",
    "        session_id=session_id,\n",
    "        actor_id=actor_id,\n",
    "        retrieval_config={\n",
    "            f\"returns/customer/{actor_id}/semantic\": RetrievalConfig(top_k=3, relevance_score=0.2),\n",
    "            f\"returns/customer/{actor_id}/preferences\": RetrievalConfig(top_k=3, relevance_score=0.2)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Create session manager\n",
    "    session_manager = AgentCoreMemorySessionManager(\n",
    "        agentcore_memory_config=agentcore_memory_config,\n",
    "        region_name=REGION\n",
    "    )\n",
    "\n",
    "    # Create the agent with all customer support tools and memory\n",
    "    agent = Agent(\n",
    "        model=bedrock_model,\n",
    "        tools=[retrieve, current_time],\n",
    "        system_prompt=system_prompt,\n",
    "        session_manager = session_manager\n",
    "    )\n",
    "\n",
    "    user_input = payload.get(\"prompt\", \"\")\n",
    "\n",
    "    # Invoke the agent\n",
    "    response = agent(user_input)\n",
    "    return response.message[\"content\"][0][\"text\"]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()  #### AGENTCORE RUNTIME - LINE 4 ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "#### What happens behind the scenes?\n",
    "\n",
    "When you use `BedrockAgentCoreApp`, it automatically:\n",
    "\n",
    "- Creates an HTTP server that listens on port 8080\n",
    "- Implements the required `/invocations` endpoint for processing requests\n",
    "- Implements the `/ping` endpoint for health checks\n",
    "- Handles proper content types and response formats\n",
    "- Manages error handling according to AWS standards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8aa1fb-4e80-4dbd-864a-8e7bf9eab714",
   "metadata": {},
   "source": [
    "### Step 3: Deploying to AgentCore Runtime\n",
    "\n",
    "Now let's deploy our agent to AgentCore Runtime using the [AgentCore Starter Toolkit](https://github.com/aws/bedrock-agentcore-starter-toolkit).\n",
    "\n",
    "#### Configure the Secure Runtime Deployment (AgentCore Runtime + AgentCore Identity)\n",
    "\n",
    "First we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we will create and a requirements file. We will also configure the identity authorization using an Amazon Cognito user pool and we will configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code\n",
    "\n",
    "<div style=\"text-align:left\"> \n",
    "    <img src=\"images/lab4_configure.png\" width=\"75%\"/> \n",
    "</div>\n",
    "\n",
    "**Note**: The Cognito access_token is valid for 2 hours only. If the access_token expires you can vend another access_token by using the `reauthenticate_user` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4581baa2-9edc-425d-becf-09968565081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those unfamiliar with Cognito: here we are creating or configuring a Cognito User Pool \n",
    "# so that users can authenticate securely and we can obtain a bearer token for API access.\n",
    "\n",
    "from utils.identity_ssm_utils import setup_cognito_user_pool, reauthenticate_user\n",
    "\n",
    "print(\"Setting up Amazon Cognito user pool...\")\n",
    "cognito_config = (\n",
    "    setup_cognito_user_pool()\n",
    ")  # You'll get your bearer token from this output cell.\n",
    "print(\"Cognito setup completed ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9013b7-9bfd-405d-9ed8-cb4de166ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "\n",
    "# Initialize the AgentCore runtime toolkit to interact with AgentCore services.\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "# Initialize an instance of the AgentCore Runtime, which allows deploying, configuring, and managing agents.\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "# Create a new IAM role specifically for the AgentCore Runtime to use when executing the agent.\n",
    "# This ensures the runtime has the necessary permissions for tasks like accessing S3, Bedrock models, and other AWS services.\n",
    "from utils.identity_ssm_utils import create_agentcore_runtime_execution_role\n",
    "agentcore_runtime_execution_role = create_agentcore_runtime_execution_role()\n",
    "\n",
    "# Configure the AgentCore agent deployment.\n",
    "# This sets up the agent's entrypoint script, runtime environment, execution role, memory mode, dependencies, \n",
    "# agent name, and authentication settings (here using Cognito JWT authorizer for secure client access).\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"lab4_runtime.py\",\n",
    "    auto_create_ecr=True,\n",
    "    execution_role=agentcore_runtime_execution_role,\n",
    "    auto_create_execution_role=False,\n",
    "    memory_mode=\"NO_MEMORY\",  # Memory was already created in a previous step, so we disable it here.\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=\"returns_refunds_agent\",\n",
    "    authorizer_configuration={\n",
    "        \"customJWTAuthorizer\": {\n",
    "            \"allowedClients\": [cognito_config.get(\"client_id\")],\n",
    "            \"discoveryUrl\": cognito_config.get(\"discovery_url\"),\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Configuration completed:\", response)\n",
    "print(f\"AllowedClients: {cognito_config.get('client_id')}\")\n",
    "print(f\"discoveryUrl: {cognito_config.get('discovery_url')}\")\n",
    "\n",
    "# Summary of what we've done so far:\n",
    "# 1. Initialized the AgentCore runtime toolkit.\n",
    "# 2. Created an execution role for AgentCore.\n",
    "# 3. Configured the agent deployment, linking it to an entrypoint script, runtime, and Cognito authorizer.\n",
    "# 4. Memory is disabled because we already created a memory instance in a previous step; it does not need to be re-created.\n",
    "# Next, we will deploy and start the agent so it can handle user queries securely and with the configured runtime environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada72f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat .bedrock_agentcore.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "#### Launch the Agent\n",
    "\n",
    "Now let's launch our agent to AgentCore Runtime. This will create an AWS CodeBuild pipeline, the Amazon ECR repository and the AgentCore Runtime components.\n",
    "\n",
    "<div style=\"text-align:left\"> \n",
    "    <img src=\"images/lab4_launch.png\" width=\"70%\"/> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the agent (this will build and deploy the container)\n",
    "# This step can take a few minutes, depending on your environment.\n",
    "# Tip: While waiting, press CTRL + A, right-click, and select **Generative AI ‚Üí Explain Code** \n",
    "# to explore or experiment with the code in the notebook interactively.\n",
    "\n",
    "from utils.identity_ssm_utils import get_ssm_parameter, put_ssm_parameter\n",
    "\n",
    "# Retrieve the knowledge base ID from SSM Parameter Store\n",
    "kb_id = get_param_value(\"/app/workshop/kb/knowledge-base-id\")\n",
    "\n",
    "# Launch the AgentCore agent, passing in environment variables for memory and knowledge base\n",
    "launch_result = agentcore_runtime.launch(\n",
    "    env_vars={\n",
    "        \"MEMORY_ID\": memory_id,\n",
    "        \"KNOWLEDGE_BASE_ID\": kb_id\n",
    "    }\n",
    ")\n",
    "print(\"Launch completed:\", launch_result.agent_arn)\n",
    "\n",
    "# Store the agent ARN in SSM Parameter Store for easy retrieval later\n",
    "agent_arn = put_ssm_parameter(\n",
    "    \"/app/returnsrefunds/agentcore/runtime_arn\",\n",
    "    launch_result.agent_arn\n",
    ")\n",
    "\n",
    "# Important note: \n",
    "# If you accidentally run this cell twice, the second run may attempt to redeploy the same agent.\n",
    "# Depending on your setup, it could overwrite the previous deployment or fail due to naming conflicts.\n",
    "# It's safest to run it only once to avoid unintended redeployments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "#### Check Deployment Status\n",
    "\n",
    "Let's wait for the deployment to complete:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Wait for the agent to be ready\n",
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint[\"status\"]\n",
    "\n",
    "end_status = [\"READY\", \"CREATE_FAILED\", \"DELETE_FAILED\", \"UPDATE_FAILED\"]\n",
    "while status not in end_status:\n",
    "    print(f\"Waiting for deployment... Current status: {status}\")\n",
    "    \n",
    "    delay = 5 * 2\n",
    "    # nosemgrep: arbitrary-sleep\n",
    "    time.sleep(delay) \n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint[\"status\"]\n",
    "\n",
    "print(f\"Final status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### Step 4: Invoking Your Deployed Agent\n",
    "\n",
    "Now that our agent is deployed and ready, let's test it with some queries. We invoke the agent with the right authorization token type. In out case it'll be Cognito access token. Copy the access token from the cell above\n",
    "\n",
    "<div style=\"text-align:left\"> \n",
    "    <img src=\"images/lab4_invoke.png\" width=\"70%\"/> \n",
    "</div>\n",
    "\n",
    "#### Using the AgentCore Starter Toolkit\n",
    "\n",
    "We can validate that the agent works using the AgentCore Starter Toolkit for invocation. The starter toolkit can automatically create a session id for us to query our agent. Alternatively, you can also pass the session id as a parameter during invocation. For demonstration purpose, we will create our own session id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "# Test different customer support scenarios\n",
    "user_query = \"I bought a Kindle Book three days ago by accident in India. I want to get a refund, what date is the ETA if I request it now?\"\n",
    "\n",
    "bearer_token = reauthenticate_user(\n",
    "    cognito_config.get(\"client_id\"),\n",
    "    cognito_config.get(\"client_secret\")\n",
    ")\n",
    "\n",
    "response = agentcore_runtime.invoke(\n",
    "    {\"prompt\": user_query},\n",
    "    bearer_token=bearer_token\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87334f72-7d5e-4fd5-bc14-4791ccd00c13",
   "metadata": {},
   "source": [
    "### Step 4.5: Demonstrating AgentCore Memory Capabilities\n",
    "\n",
    "Now that our agent is deployed and running in production, let's explore how **AgentCore Memory** enables personalized, context-aware interactions across sessions.\n",
    "\n",
    "AgentCore Memory operates on two levels:\n",
    "- **Short-Term Memory (STM)**: Immediate conversation context within the current session\n",
    "- **Long-Term Memory (LTM)**: Persistent information extracted across multiple conversations, including customer preferences and facts\n",
    "\n",
    "In this section, we'll:\n",
    "1. Seed some customer interaction history\n",
    "2. Wait for Long-Term Memory processing to complete\n",
    "3. Test how the agent uses memory to provide personalized responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a10e19-583e-449d-a862-c54c67b773aa",
   "metadata": {},
   "source": [
    "#### Seeding Customer Interaction History\n",
    "\n",
    "Let's seed some previous customer interactions to demonstrate how memory works. In production, this happens naturally through customer conversations, but for this demo we'll create some historical context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d56e4-164a-433d-990c-7e1411955b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from utils import get_param_value\n",
    "\n",
    "# Initialize memory client\n",
    "memory_client = MemoryClient(region_name=region)\n",
    "\n",
    "print(f\"Memory ID: {memory_id}\")\n",
    "\n",
    "# Define a customer ID for this demo\n",
    "ACTOR_ID = \"customer_001\"\n",
    "\n",
    "# Seed previous customer interactions\n",
    "previous_interactions = [\n",
    "    (\"I bought a Fire TV Stick last week in the US but it's not working properly. Can I return it?\", \"USER\"),\n",
    "    (\"Yes, you can return your Fire TV Stick. According to the US return policy, most items can be returned within 30 days of receipt. Since you purchased it last week, you're well within the return window.\", \"ASSISTANT\"),\n",
    "    (\"I also purchased a Kindle Paperwhite 2 months ago in the UK. Can I still return that?\", \"USER\"),\n",
    "    (\"For the Kindle Paperwhite purchased in the UK 2 months ago, you're outside the standard 30-day return window. However, Kindle devices may have different warranty coverage. Let me check the specific UK policy for you.\", \"ASSISTANT\"),\n",
    "    (\"I prefer shopping for electronics and usually buy Amazon devices. I'm in the US.\", \"USER\"),\n",
    "    (\"Thank you for sharing that! I've noted your preference for Amazon electronics devices and that you're based in the US. This will help me provide more relevant assistance in the future.\", \"ASSISTANT\"),\n",
    "]\n",
    "\n",
    "print(\"üìù Seeding customer interaction history...\")\n",
    "try:\n",
    "    memory_client.create_event(\n",
    "        memory_id=memory_id,\n",
    "        actor_id=ACTOR_ID,\n",
    "        session_id=\"previous_session\",\n",
    "        messages=previous_interactions\n",
    "    )\n",
    "    print(\"‚úÖ Customer history seeded successfully!\")\n",
    "    print(\"‚è≥ Long-Term Memory processing will begin automatically...\")\n",
    "    print(\"   This typically takes 20-30 seconds as the system:\")\n",
    "    print(\"   ‚Ä¢ Analyzes conversation patterns\")\n",
    "    print(\"   ‚Ä¢ Extracts customer preferences\")\n",
    "    print(\"   ‚Ä¢ Creates semantic embeddings for facts\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error seeding history: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67babc91-0114-4b6a-9e40-89ae5e481f71",
   "metadata": {},
   "source": [
    "#### Waiting for Long-Term Memory Processing\n",
    "\n",
    "After creating events, AgentCore Memory processes the data asynchronously:\n",
    "1. **Immediate**: Messages stored in Short-Term Memory (STM)\n",
    "2. **Asynchronous**: STM processed into Long-Term Memory (LTM) strategies\n",
    "\n",
    "Let's wait for the processing to complete and verify the memories were extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887df85-d573-48d1-9d88-1353fcb4e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for Long-Term Memory processing\n",
    "print(\"üîç Checking for processed Long-Term Memories...\")\n",
    "retries = 0\n",
    "max_retries = 6  # 1 minute wait\n",
    "memories_found = False\n",
    "\n",
    "while retries < max_retries:\n",
    "    try:\n",
    "        # Check for preference memories\n",
    "        preference_memories = memory_client.retrieve_memories(\n",
    "            memory_id=memory_id,\n",
    "            namespace=f\"returns/customer/{ACTOR_ID}/preferences\",\n",
    "            query=\"customer preferences and location\"\n",
    "        )\n",
    "        \n",
    "        if preference_memories:\n",
    "            print(f\"‚úÖ Found {len(preference_memories)} preference memories after {retries * 10} seconds!\")\n",
    "            memories_found = True\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error retrieving memories: {e}\")\n",
    "    \n",
    "    retries += 1\n",
    "    if retries < max_retries:\n",
    "        print(f\"‚è≥ Still processing... waiting 10 more seconds (attempt {retries}/{max_retries})\")\n",
    "        time.sleep(10)\n",
    "\n",
    "if not memories_found:\n",
    "    print(\"‚ö†Ô∏è Memory processing is taking longer than expected. This can happen with system load.\")\n",
    "    print(\"   You can proceed with the lab - memories will be available shortly.\")\n",
    "else:\n",
    "    print(\"\\nüéØ AgentCore Memory extracted these customer preferences:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, memory in enumerate(preference_memories, 1):\n",
    "        if isinstance(memory, dict):\n",
    "            content = memory.get('content', {})\n",
    "            if isinstance(content, dict):\n",
    "                text = content.get('text', '')\n",
    "                if text:\n",
    "                    print(f\"  {i}. {text}\")\n",
    "    \n",
    "    # Also check semantic memories\n",
    "    try:\n",
    "        semantic_memories = memory_client.retrieve_memories(\n",
    "            memory_id=memory_id,\n",
    "            namespace=f\"returns/customer/{ACTOR_ID}/semantic\",\n",
    "            query=\"previous return requests and purchases\"\n",
    "        )\n",
    "        \n",
    "        if semantic_memories:\n",
    "            print(\"\\nüß† AgentCore Memory identified these factual details:\")\n",
    "            print(\"=\" * 80)\n",
    "            for i, memory in enumerate(semantic_memories, 1):\n",
    "                if isinstance(memory, dict):\n",
    "                    content = memory.get('content', {})\n",
    "                    if isinstance(content, dict):\n",
    "                        text = content.get('text', '')\n",
    "                        if text:\n",
    "                            print(f\"  {i}. {text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error retrieving semantic memories: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5755fcc-532c-45df-9515-f9228372cbaf",
   "metadata": {},
   "source": [
    "#### Testing Memory-Aware Responses\n",
    "\n",
    "Now let's test how the agent uses memory to provide personalized responses. We'll ask questions that should trigger memory retrieval and demonstrate context awareness.\n",
    "\n",
    "**Note**: The agent's memory hooks automatically:\n",
    "1. Retrieve relevant customer context before processing queries\n",
    "2. Inject that context into the conversation\n",
    "3. Save new interactions for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4dd5fb-63ff-419b-8cdb-efff63f1ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new session for this customer\n",
    "import uuid\n",
    "demo_session_id = str(uuid.uuid4())\n",
    "\n",
    "print(\"üß™ Testing memory-aware agent responses...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test 1: Ask about previous purchases (should recall Fire TV Stick and Kindle)\n",
    "print(\"\\nüì± Test 1: Asking about previous purchases...\\n\")\n",
    "test_query_1 = \"What products have I purchased recently?\"\n",
    "\n",
    "bearer_token = reauthenticate_user(\n",
    "    cognito_config.get(\"client_id\"), \n",
    "    cognito_config.get(\"client_secret\")\n",
    ")\n",
    "\n",
    "response_1 = agentcore_runtime.invoke(\n",
    "    {\"prompt\": test_query_1}, \n",
    "    bearer_token=bearer_token,\n",
    "    session_id=demo_session_id\n",
    ")\n",
    "print(f\"Agent Response: {response_1}\\n\")\n",
    "\n",
    "# Test 2: Ask for recommendations (should use preference for Amazon devices)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüéØ Test 2: Asking for product recommendations...\\n\")\n",
    "test_query_2 = \"I'm thinking about buying a new tablet. What would you recommend?\"\n",
    "\n",
    "response_2 = agentcore_runtime.invoke(\n",
    "    {\"prompt\": test_query_2}, \n",
    "    bearer_token=bearer_token,\n",
    "    session_id=demo_session_id\n",
    ")\n",
    "print(f\"Agent Response: {response_2}\\n\")\n",
    "\n",
    "# Test 3: Follow-up question (should maintain session context)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüí¨ Test 3: Follow-up question using session context...\\n\")\n",
    "test_query_3 = \"What's the return policy for that?\"\n",
    "\n",
    "response_3 = agentcore_runtime.invoke(\n",
    "    {\"prompt\": test_query_3}, \n",
    "    bearer_token=bearer_token,\n",
    "    session_id=demo_session_id\n",
    ")\n",
    "print(f\"Agent Response: {response_3}\\n\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚úÖ Memory demonstration complete!\")\n",
    "print(\"\\nNotice how the agent:\")\n",
    "print(\"  ‚Ä¢ Recalled previous purchases (Fire TV Stick, Kindle Paperwhite)\")\n",
    "print(\"  ‚Ä¢ Used customer preferences (Amazon devices, US location)\")\n",
    "print(\"  ‚Ä¢ Maintained context within the session for follow-up questions\")\n",
    "print(\"\\nThis is the power of AgentCore Memory in production! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82b1ee",
   "metadata": {},
   "source": [
    "### Step 5: AgentCore Observability\n",
    "\n",
    "[AgentCore Observability](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/observability.html) provides monitoring and tracing capabilities for AI agents using Amazon OpenTelemetry Python Instrumentation and Amazon CloudWatch GenAI Observability.\n",
    "\n",
    "#### Agents\n",
    "\n",
    "Default AgentCore Runtime configuration allows for logging our agent's traces on CloudWatch by means of **AgentCore Observability**. These traces can be seen on the AWS CloudWatch GenAI Observability dashboard. Navigate to Cloudwatch &rarr; GenAI Observability &rarr; Bedrock AgentCore.\n",
    "\n",
    "![Agents Overview on CloudWatch](images/lab4_observability_agents.png)\n",
    "\n",
    "#### Sessions\n",
    "\n",
    "The Sessions view shows the list of all the sessions associated with all agents in your account.\n",
    "\n",
    "![sessions](images/lab4_sessions_observability.png)\n",
    "\n",
    "#### Traces\n",
    "\n",
    "Trace view lists all traces from your agents in this account. To work with traces:\n",
    "\n",
    "- Choose Filter traces to search for specific traces.\n",
    "- Sort by column name to organize results.\n",
    "- Under Actions, select Logs Insights to refine your search by querying across your log and span data or select Export selected traces to export.\n",
    "\n",
    "![traces](images/lab4_traces_observability.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75904853-e8a3-4e2b-81bf-cb60dfed6f92",
   "metadata": {},
   "source": [
    "### Step 6: Building a Customer-Facing Frontend Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080b8f0-a8a3-42e3-9eec-fb0bb9cd52bd",
   "metadata": {},
   "source": [
    "You can now invoke your agent runtime from any application. On real world applications, customers expect an user interface to be available. Now it's time to create a user-friendly frontend that customers can actually use to interact with our agent.\n",
    "\n",
    "We'll now create a **Streamlit-based web application** that provides customers with an intuitive chat interface to interact with our deployed Customer Support Agent. The frontend will include:\n",
    "\n",
    "- **Secure Authentication** - User login via Amazon Cognito\n",
    "- **Real-time Chat Interface** - Streamlit-powered conversational UI\n",
    "- **Streaming Responses** - Live response streaming for better user experience\n",
    "- **Session Management** - Persistent conversations with memory\n",
    "- **Response Timing** - Performance metrics for transparency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05e7c0-c92e-4d77-9f80-0c7373ea58aa",
   "metadata": {},
   "source": [
    "#### Install Frontend Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec7d9b-5b8c-47f5-912c-47c1bb7729b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install frontend-specific dependencies\n",
    "%pip install -r utils/lab4_frontend/requirements.txt -q\n",
    "print(\"‚úÖ Frontend dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf31ca-713e-42eb-960f-f3d0e70bb90b",
   "metadata": {},
   "source": [
    "Understanding the Frontend Architecture\n",
    "\n",
    "Our Streamlit application consists of several key components:\n",
    "\n",
    "#### Core Components:\n",
    "\n",
    "1. **main.py** - Main Streamlit application with UI and authentication\n",
    "2. **chat.py** - Chat management and AgentCore Runtime integration\n",
    "3. **chat_utils.py** - Utility functions for message formatting and display\n",
    "4. **sagemaker_helper.py** - Helper for generating accessible URLs\n",
    "\n",
    "#### Authentication Flow:\n",
    "\n",
    "1. User accesses the Streamlit application\n",
    "2. Amazon Cognito handles user authentication\n",
    "3. Valid JWT tokens are used to authorize AgentCore Runtime requests\n",
    "4. User can interact with the Customer Support Agent securely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f992b70-ab2c-4fb0-ba7c-9ec43d769c8b",
   "metadata": {},
   "source": [
    "#### Launch the Returns and Refunds Agent Frontend üöÄ\n",
    "\n",
    "Now let's start our Streamlit application. The application will:\n",
    "\n",
    "1. **Generate an accessible URL** for the application\n",
    "2. **Start the Streamlit server** on port 8501\n",
    "3. **Connect to your deployed AgentCore Runtime** from Lab 4\n",
    "4. **Provide a complete customer support interface**\n",
    "\n",
    "**Important Notes:**\n",
    "- The application will run continuously until you stop it (Ctrl+C)\n",
    "- Make sure your AgentCore Runtime from Lab 4 is still deployed and running\n",
    "- The Cognito authentication tokens are valid for 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bdb66b-7c5a-408a-9bfe-e2e93eab5015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accessible URL for the Streamlit application\n",
    "from utils.lab4_frontend.sagemaker_helper import get_streamlit_url\n",
    "\n",
    "streamlit_url = get_streamlit_url()\n",
    "print(f'\\nüöÄ Returns and Refunds Agent Streamlit Application URL:\\n{streamlit_url}\\n')\n",
    "\n",
    "# Start the Streamlit application\n",
    "!cd utils/lab4_frontend/ && streamlit run main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35960ba6-d262-47d0-bb73-f027c38f2857",
   "metadata": {},
   "source": [
    "#### Testing Your Returns and Refunds Agent Application\n",
    "\n",
    "Once your Streamlit application is running, you can test the complete customer support experience:\n",
    "\n",
    "#### Authentication Testing:\n",
    "1. **Access the application** using the Returns and Refunds Agent Streamlit Application URL provided above\n",
    "2. **Sign in** with the test credentials provided in the output\n",
    "3. **Verify** that you see the welcome message with your username\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/lab4_streamlit_login.png\"/>\n",
    "</div>\n",
    "<div>\n",
    "    <img src=\"images/lab4_welcome_user.png\"/>\n",
    "</div>    \n",
    "\n",
    "\n",
    "#### Scenarios to Test:\n",
    "\n",
    "\n",
    "\n",
    "Return Policy Questions:\n",
    "I bought a Kindle Book three days ago by accident in India. I want to get a refund, what date is the ETA if I request it now?\"\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">    \n",
    "    <img src=\"images/lab4_agent_question.png\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "Memory and Personalization Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c243e86-a214-483c-aef1-d5243f28ca9e",
   "metadata": {},
   "source": [
    "### Congratulations! üéâ\n",
    "\n",
    "You have successfully completed **Lab 4: Deploy to Production - Use AgentCore Runtime with Observability and a Frontend Application!**\n",
    "\n",
    "Here is what you accomplished:\n",
    "\n",
    "##### Production-Ready Deployment:\n",
    "\n",
    "- Prepared your agent for production with minimal code changes (only 4 lines added)\n",
    "- Validated proper session isolation between different customers\n",
    "- Confirmed session continuity + memory persistence and context awareness per session\n",
    "\n",
    "##### Enterprise-Grade Security & Identity:\n",
    "\n",
    "- Implemented secure authentication using Cognito integration with JWT tokens\n",
    "- Configured proper IAM roles and execution permissions for production workloads\n",
    "- Established identity-based access control for secure agent invocation\n",
    "\n",
    "##### Comprehensive Observability:\n",
    "\n",
    "- Enabled AgentCore Observability for full request tracing across all customer sessions\n",
    "- Configured CloudWatch GenAI Observability dashboard monitoring\n",
    "\n",
    "##### Built a customer facing front-end application\n",
    "\n",
    "- **Web Interface** - Streamlit-based customer support application\n",
    "- **Secure Authentication** - Amazon Cognito integration for user management\n",
    "- **Real-time Streaming** - Live response streaming for better user experience\n",
    "- **Session Management** - Persistent conversations with memory across interactions\n",
    "- **Complete Integration** - Frontend connected to your AgentCore Runtime\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To further enhance your customer support solution, consider:\n",
    "\n",
    "- **Custom Styling** - Brand the frontend with your company's design system\n",
    "- **Additional Tools** - Integrate with your existing CRM, ticketing, or knowledge base systems\n",
    "- **Multi-language Support** - Add internationalization for global customers\n",
    "- **Advanced Analytics** - Implement custom dashboards for support team insights\n",
    "- **Mobile Optimization** - Ensure the interface works well on mobile devices\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "When you're ready to clean up the resources created in this workshop:\n",
    "\n",
    "**Ready to clean up?** [Proceed to Lab 6: Cleanup ‚Üí](lab6_Cleanup.ipynb)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
