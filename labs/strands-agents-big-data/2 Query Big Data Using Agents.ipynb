{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GOAL - Query big data using AI Agents without writing big data analytics code. <br>\n",
        "The AI Agent will use built-in strands tools and MCP server to get the job done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "Install required dependencies for the notebook including Strands SDK, AWS SDK, and MCP client libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T02:33:39.624651Z",
          "iopub.status.busy": "2025-10-16T02:33:39.623746Z",
          "iopub.status.idle": "2025-10-16T02:33:39.628882Z",
          "shell.execute_reply": "2025-10-16T02:33:39.628108Z",
          "shell.execute_reply.started": "2025-10-16T02:33:39.624612Z"
        }
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%m/%d %H:%M:%S',\n",
        "    filename='strands_debug.log'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-Requisites\n",
        "You have run the Notebook 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Dependencies and AWS Configuration\n",
        "Import required libraries and configure AWS settings for the data processing workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T02:33:47.295947Z",
          "iopub.status.busy": "2025-10-16T02:33:47.295422Z",
          "iopub.status.idle": "2025-10-16T02:33:48.253875Z",
          "shell.execute_reply": "2025-10-16T02:33:48.253263Z",
          "shell.execute_reply.started": "2025-10-16T02:33:47.295915Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os, time, boto3, json\n",
        "from strands import Agent, tool\n",
        "from strands.models import BedrockModel\n",
        "from strands_tools import use_aws, file_write, file_read, file_write, sleep, python_repl\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, List\n",
        "\n",
        "# Bypass tool consent for automated execution\n",
        "os.environ[\"BYPASS_TOOL_CONSENT\"] = \"true\"\n",
        "# Specify that if python_repl tool is used, it shouldnt wait for user interaction\n",
        "os.environ[\"PYTHON_REPL_INTERACTIVE\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Metadata Info from the json file that we created in the previous notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T02:34:09.506044Z",
          "iopub.status.busy": "2025-10-16T02:34:09.505229Z",
          "iopub.status.idle": "2025-10-16T02:34:09.512283Z",
          "shell.execute_reply": "2025-10-16T02:34:09.511639Z",
          "shell.execute_reply.started": "2025-10-16T02:34:09.506015Z"
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Read the file metadata.json into a dictionary without using file_read\n",
        "with open('metadata.json', 'r') as f:\n",
        "    db_metadata = json.load(f)\n",
        "db_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MCP Client Setup\n",
        "We wll get tools exposed by an MCP server to discover partition columns and keys from the data in S3.<br><br>\n",
        "Initialize the AWS Data Processing MCP server client to provide AI agents with AWS Glue, EMR, and Athena capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up a session\n",
        "import boto3\n",
        "import os\n",
        "\n",
        "##### CHOOSE THE MOST FIT AWS CREDENTIAL FOR YOUR AWS ENVIRONMENT \n",
        "\n",
        "# Option1: Default session\n",
        "session = boto3.session.Session()\n",
        "\n",
        "# Option2: Using AWS profile defined in ~/.aws/config\n",
        "#session = boto3.session.Session(profile_name=\"<YOUR-AWS-PROFILE-NAME>\")\n",
        "\n",
        "# Option3: Explicit credentials\n",
        "#session = boto3.session.Session(\n",
        "#    aws_access_key_id='YOUR_ACCESS_KEY_ID',\n",
        "#    aws_secret_access_key='YOUR_SECRET_ACCESS_KEY',\n",
        "#    aws_session_token='YOUR_SESSION_TOKEN')\n",
        "# Extract session data\n",
        "import boto3\n",
        "\n",
        "region = session.region_name\n",
        "sts_client = session.client(\"sts\")\n",
        "response = sts_client.get_caller_identity()\n",
        "account_id = response.get(\"Account\")\n",
        "print(\"Sesseion = \", region, account_id)\n",
        "\n",
        "credentials = session.get_credentials()\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = credentials.access_key\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = credentials.secret_key\n",
        "os.environ[\"AWS_SESSION_TOKEN\"] = credentials.token\n",
        "os.environ[\"AWS_REGION\"] = region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T02:34:14.451885Z",
          "iopub.status.busy": "2025-10-16T02:34:14.451524Z",
          "iopub.status.idle": "2025-10-16T02:34:15.046692Z",
          "shell.execute_reply": "2025-10-16T02:34:15.045967Z",
          "shell.execute_reply.started": "2025-10-16T02:34:14.451859Z"
        }
      },
      "outputs": [],
      "source": [
        "# Import MCP client libraries\n",
        "from mcp import stdio_client, StdioServerParameters\n",
        "from strands.tools.mcp import MCPClient\n",
        "\n",
        "# Create MCP client for AWS data processing server\n",
        "# This provides tools for Glue, EMR, and Athena operations\n",
        "import boto3\n",
        "\n",
        "# Create MCP client for AWS data processing server\n",
        "# This provides tools for Glue, EMR, and Athena operations\n",
        "data_mcp_client = MCPClient(lambda: stdio_client(\n",
        "    StdioServerParameters(\n",
        "        command=\"uvx\",  # Use uvx to run the MCP server\n",
        "        args= [\n",
        "            \"awslabs.aws-dataprocessing-mcp-server@latest\",\n",
        "            \"--allow-write\",  # Enable write operations\n",
        "        ],\n",
        "        env= {\n",
        "            \"AWS_ACCESS_KEY_ID\": os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
        "            \"AWS_SECRET_ACCESS_KEY\": os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
        "            \"AWS_SESSION_TOKEN\": os.environ[\"AWS_SESSION_TOKEN\"],\n",
        "            \"FASTMCP_LOG_LEVEL\": \"ERROR\",  # Minimize logging noise\n",
        "            \"AWS_REGION\": session.region_name      # Set AWS region\n",
        "      }\n",
        "    )\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Let's Ask Natural Language Questions to AI Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T02:35:13.702953Z",
          "iopub.status.busy": "2025-10-16T02:35:13.702359Z",
          "iopub.status.idle": "2025-10-16T02:35:13.709801Z",
          "shell.execute_reply": "2025-10-16T02:35:13.708702Z",
          "shell.execute_reply.started": "2025-10-16T02:35:13.702921Z"
        }
      },
      "outputs": [],
      "source": [
        "from utils_big_data import print_tokens_costs, load_system_prompt_from_file\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Let's load the system prompt from file for running queries on data in S3 data lake\n",
        "query_system_prompt = load_system_prompt_from_file(\"text_to_sql_prompt.txt\", db_metadata=db_metadata)\n",
        "display(Markdown(query_system_prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T02:35:31.268221Z",
          "iopub.status.busy": "2025-10-16T02:35:31.267943Z",
          "iopub.status.idle": "2025-10-16T02:35:31.274170Z",
          "shell.execute_reply": "2025-10-16T02:35:31.273463Z",
          "shell.execute_reply.started": "2025-10-16T02:35:31.268200Z"
        }
      },
      "outputs": [],
      "source": [
        "model_list = ['deepseek.v3-v1:0', \n",
        "            'qwen.qwen3-coder-30b-a3b-v1:0',\n",
        "            'us.anthropic.claude-3-7-sonnet-20250219-v1:0',\n",
        "            'us.anthropic.claude-sonnet-4-20250514-v1:0',\n",
        "            'openai.gpt-oss-20b-1:0',\n",
        "            'openai.gpt-oss-120b-1:0',\n",
        "            'us.anthropic.claude-haiku-4-5-20251001-v1:0']\n",
        "\n",
        "# We will use the following model in Strands Agent\n",
        "model_id = \"us.anthropic.claude-haiku-4-5-20251001-v1:0\"\n",
        "\n",
        "# Let's create a reusable function to process a query and return a response in a structured dictionary format\n",
        "def  get_query_response(query, model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\"):\n",
        "\n",
        "    # We want the response to be in structured dictionary format that returns SQL statement, its reasoning and the final response.\n",
        "    class SQLQuery(BaseModel):\n",
        "        sql_statement: str = Field(description=\"The SQL query that was generated\")\n",
        "        reasoning: str = Field(description=\"Step by step explanation of how the natural language question was translated to this SQL statement\")\n",
        "\n",
        "    class QueryResponse(BaseModel):        \n",
        "        sql_queries: List[SQLQuery] = Field(description=\"List of SQL queries with their reasoning\")\n",
        "        final_response: str = Field(description=\"The final response generated\")\n",
        "\n",
        "    # Cerate the Bedrock Model using model_id\n",
        "    model = BedrockModel(model_id=model_id, boto_session=session)\n",
        "\n",
        "    #Let's us ethe MCP client we created earlier\n",
        "    with data_mcp_client:\n",
        "        # Get the data processing tools from MCP server\n",
        "        data_tools = data_mcp_client.list_tools_sync()\n",
        "\n",
        "        # Optimize tools by passing just what we need instead of all 32 tools\n",
        "        curated_data_tools = ['manage_aws_athena_query_executions']\n",
        "\n",
        "        # Extract just the tools that we need.\n",
        "        filtered_tools = [tool for tool in data_tools if tool.tool_name in curated_data_tools]\n",
        "\n",
        "        #Add the following tools so we can generate charts or read / write to files if needed.\n",
        "        final_tools = [python_repl, file_read, file_write] + filtered_tools\n",
        "    \n",
        "        # Pass the system prompt, the LLM we use with bedrock, and all the tools to the agent\n",
        "        data_lake_agent = Agent(system_prompt = query_system_prompt, model=model, tools=final_tools)\n",
        "\n",
        "        # Invoke the Agent\n",
        "        temp_response = data_lake_agent(query)\n",
        "\n",
        "        #Convert the agents response into a structured output\n",
        "        response = data_lake_agent.structured_output(QueryResponse, \"Extract the structured output of sql queries, reasoning, and the final response\")\n",
        "\n",
        "        #Convert the object into a dictionary\n",
        "        response_dict = response.model_dump()\n",
        "        return response_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-16T02:35:34.343379Z",
          "iopub.status.busy": "2025-10-16T02:35:34.342744Z",
          "iopub.status.idle": "2025-10-16T02:36:14.384572Z",
          "shell.execute_reply": "2025-10-16T02:36:14.383798Z",
          "shell.execute_reply.started": "2025-10-16T02:35:34.343350Z"
        }
      },
      "outputs": [],
      "source": [
        "response = get_query_response(f\"How many rides went to Airport each month in 2025?\")\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_query_response(f\"How many taxi vendors are there? Plot a bar chart with ride count and fare amount.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = get_query_response(\"For the top 25 percentile of ride fares per yellow / green class, what is ratio of tips to total fare? If I am a taxi driver which routes and times should I drive to get the most tips?\")\n",
        "pprint(response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "thalaiva",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}