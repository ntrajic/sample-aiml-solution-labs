{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f24ab8a0-0664-4fb1-9485-03046e7c0a41",
      "metadata": {},
      "source": [
        "# Observing Agentic AI with MLflow, AWS AgentCore, and Strands\n",
        "## Introduction\n",
        "Observability is a critical aspect of building and deploying reliable and high-performing Agentic AI systems. By integrating MLflow, AWS AgentCore, and Strands Agents, you can achieve comprehensive observability across the entire lifecycle of your AI agents, from development to production.\n",
        "## Observability with MLflow and Strands Agents\n",
        "MLflow provides native integration with Strands Agents, offering automatic tracing and monitoring capabilities. By enabling auto-logging, MLflow captures valuable information about your agent's execution, including:\n",
        "- Agent Execution Traces: Complete workflow execution paths and decision points\n",
        "- Tool Usage Metrics: Performance and success rates of individual tools\n",
        "- Token Usage and Costs: Resource consumption tracking for cost optimization\n",
        "- Latency Measurements: Response times across different components\n",
        "- Error Tracking: Exception handling and failure analysis\n",
        "This integration allows you to gain deep insights into your agent's behavior and performance, enabling you to iterate quickly and ensure the quality of your Agentic AI applications.\n",
        "\n",
        "## Unified Observability Architecture\n",
        "By combining the capabilities of MLflow, Strands Agents, and AWS AgentCore, you can achieve a three-layer observability approach:\n",
        "1. **Application Layer (MLflow)**: Experiment tracking, model versioning, and artifact management\n",
        "2. **Agent Runtime Layer (Strands + AgentCore)**: Agent execution tracing, workflow coordination monitoring, and tool performance analytics\n",
        "3. **Infrastructure Layer (AWS Services)**: System metrics, distributed tracing, and resource utilization tracking\n",
        "This unified approach provides a comprehensive view of your Agentic AI system, enabling you to monitor key performance metrics, troubleshoot issues, and optimize your applications for cost and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f315a2-5303-4a41-97ab-c16d327655eb",
      "metadata": {},
      "source": [
        "⚠️ **A MLflow tracking server is already configured if you are running this notebook with AWS provided account** <br/>\n",
        "⚠️ **If you are using your own AWS account, configure an MLflow tracking server in your SageMaker Studio. Please refer:** https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow-create-tracking-server.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1a7073-4679-48f1-b814-debba08a88d1",
      "metadata": {},
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b980e49-ca0a-4b6a-9929-bc44d369de17",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --force-reinstall -U -r requirements.txt --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf87184-96a9-4a38-b628-2ccce88bf1a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import boto3\n",
        "\n",
        "session = boto3.Session()\n",
        "\n",
        "sts = session.client('sts')\n",
        "identity = sts.get_caller_identity()\n",
        "account_id = identity['Account']\n",
        "region = boto3.Session().region_name or 'us-west-2'\n",
        "\n",
        "print(f\"Account ID: {account_id}\")\n",
        "print(f\"Region: {region}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8beada14-d768-4423-a828-2240b8df6f8e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T16:39:42.871460Z",
          "iopub.status.busy": "2025-10-07T16:39:42.871181Z",
          "iopub.status.idle": "2025-10-07T16:39:43.159074Z",
          "shell.execute_reply": "2025-10-07T16:39:43.158450Z",
          "shell.execute_reply.started": "2025-10-07T16:39:42.871440Z"
        }
      },
      "outputs": [],
      "source": [
        "# Read variables\n",
        "from utils import get_param_value\n",
        "mlflow_tracking_server_arn = get_param_value(\"/app/workshop/tracking-server/arn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25c46bc1-6abd-495b-a27c-188e2712afbd",
      "metadata": {},
      "source": [
        "⚠️ **If you are running this notebook in your own account, please replace the variables with your own resource names & ARNs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0218ac09-c802-4b80-88e7-2c29d3640790",
      "metadata": {},
      "outputs": [],
      "source": [
        "# mlflow_tracking_server_arn=\"<PLACEHOLDER>\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}